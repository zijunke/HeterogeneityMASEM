---
title: "MED_NoCovariate"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 4
    number_sections: yes
  html_document: default
  word_document:
    toc: yes
    toc_depth: '4'
    number_sections: yes
---

```{r setup, include=FALSE, echo = F}
require("knitr")
#knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir = getwd())
opts_knit$set(root.dir = 'D:/Research/2023/CompareMASEM/MED/NoCovariate/')
```

# Load packages & set working directory & read in data
```{r}
library(matrixcalc);library(MASS);library(Matrix)
library(coda);library(R2OpenBUGS);library(metaSEM)
library(xlsx)

# Working directory
wd = 'D:/Research/2023/CompareMASEM/MED/'
setwd(paste0(wd,'NoCovariate/'))

# Read in data
dat = read.xlsx(paste0(wd,'data3.xlsx'),1) 
head(dat)

wd = paste0(wd,'NoCovariate/')
```

# Functions
```{r}
# vector to matrix
v2m <- function(vec,p,corr= T){
	M = matrix(0,p,p)
	M[lower.tri(M)] = vec
	M = M + t(M)
	if(corr==TRUE){
		diag(M) = 1
	}else{
		diag(M) = diag(M)/2
	}
	return(M)
}

# impute missing values in covariance / correlation matrices of each study
# to obtain a rough estimate of the covariance matrix of covariance / correlation matrix
# weighted average correlation
Mimpute <- function(R,N,missing){
	if(is.null(missing)){
		return(R)
	}else{
		na.pos = which(is.na(R),arr.ind = TRUE)
		mu.N = mean(N)
		Rbar = apply(R,2,mean,na.rm = TRUE)# Becker's mean r
		
		for(coli in unique(na.pos[,2])){
			id = na.pos[(na.pos[,2] == coli),1]
			R[id,coli] = Rbar[coli]
		}
		return(R)
	}
}

# change the coordinating system of a vectorized matrix to the coordinating system of 
# the original matrix
# e.g., from vS to S, the former uses one coordinate (vil), whereas the latter uses two (j,k).
Get.vi2jk <- function(p,diag.incl=FALSE,byrow=FALSE){
	A = matrix(1,p,p)
	if(diag.incl ==FALSE){
		pp = p*(p-1)/2
		vi2jk <- matrix(NA,pp,3)
		vi2jk[,3] <- 1:pp
		if(byrow == FALSE){
			vi2jk[,1:2] <- which(lower.tri(A)==1,arr.ind = TRUE)
		}else{
			vi2jk[,1:2] <- which(upper.tri(A)==1,arr.ind = TRUE)
		}
		colnames(vi2jk) = c('j','k','vi')
	}else{
		pp = p*(p+1)/2
		vi2jk <- matrix(NA,pp,3)
		vi2jk[,3] <- 1:pp
		if(byrow == FALSE){
			vi2jk[,1:2] <- which(lower.tri(A,diag = TRUE)==1,arr.ind = TRUE)
		}else{
			vi2jk[,1:2] <- which(upper.tri(A,diag = TRUE)==1,arr.ind = TRUE)
		}
		colnames(vi2jk) = c('j','k','vi')		
	}
	return(vi2jk)
}

# change the coordinating system of a matrix to the coordinating system of 
# the corresponding vectorized matrix
# e.g., from S to vS, the former uses two coordinates (j,k), whereas the latter uses only one (vil).
Get.jk2vi <- function(vi2jk,p,diag.incl=FALSE){
	jk2vi = matrix(0,p,p)
	jk2vi[vi2jk[,1:2]] = vi2jk[,3]
	if(diag.incl){
		jk2vi = jk2vi + t(jk2vi)
		diag(jk2vi) = diag(jk2vi)/2
	}else{
		pp = p*(p-1)/2
		jk2vi = jk2vi + t(jk2vi) + diag(rep(pp+1,p))
	}
	return(jk2vi)
}

jkvil <- function(p){
	vi2jk	= Get.vi2jk(p)
	j	= vi2jk[,1]
	k	= vi2jk[,2]
	vil	= Get.jk2vi(vi2jk,p)
	return(list(j=j,k=k,vil=vil))
}

# compute the covariance matrix of correlation matrix
# based on Steiger (1980)
Corr.Cov <- function(vR,N,index.list){
	nvR	= length(vR)
	vR	= c(vR,1)
	NvR.cov = matrix(NA,nvR,nvR)
	j = index.list$j
	k = index.list$k
	vil = index.list$vil

	for(vi in 1:nvR){
		NvR.cov[vi,vi] = (1-(vR[vi])^2)^2
	}
	for(vi in 1:(nvR-1)){
	for(vj in (vi+1):nvR){
		NvR.cov[vi,vj] = ((vR[vil[j[vi],j[vj]]]-vR[vi]*vR[vil[k[vi],j[vj]]])*(vR[vil[k[vi],k[vj]]]-vR[vil[k[vi],j[vj]]]*vR[vj])
		 +(vR[vil[j[vi],k[vj]]]-vR[vil[j[vi],j[vj]]]*vR[vj])*(vR[vil[k[vi],j[vj]]]-vR[vi]*vR[vil[j[vi],j[vj]]])
		 +(vR[vil[j[vi],j[vj]]]-vR[vil[j[vi],k[vj]]]*vR[vj])*(vR[vil[k[vi],k[vj]]]-vR[vi]*vR[vil[j[vi],k[vj]]])
		 +(vR[vil[j[vi],k[vj]]]-vR[vi]*vR[vil[k[vi],k[vj]]])*(vR[vil[j[vj],k[vi]]]-vR[vil[k[vi],k[vj]]]*vR[vj]))/2
		NvR.cov[vj,vi] <- NvR.cov[vi,vj]
	}
	}

	vR.cov = NvR.cov/(N)
	vR.cov = as.matrix(nearPD(vR.cov,posd.tol = 1e-5)$mat)
	return(vR.cov)
}

# Use average correlation vector to compute V_psi
Vj <- function(vR.bar,N,pp,Nstudy,index.list){

	mu.N = mean(N)
	S.vR.bar = Corr.Cov(vR.bar,mu.N,index.list)
	inv.S.vR.bar = solve(S.vR.bar)
	tau.vR = array(NA,dim = c(Nstudy,pp,pp))
	S.vR = array(NA,dim = c(Nstudy,pp,pp))
	for(i in 1:Nstudy){
		S.vR[i,,]<- S.vR.bar/N[i]*mu.N
		tau.vR[i,,] <- inv.S.vR.bar/mu.N*N[i]
	}	
	return(list(S.vR = S.vR,tau.vR = tau.vR))
}

# Use individual correlation vectors to compute V_psi
Vj2 <- function(vR.impute,N,pp,Nstudy,index.list){

	tau.vR = array(NA,dim = c(Nstudy,pp,pp))
	S.vR = array(NA,dim = c(Nstudy,pp,pp))
	for(i in 1:Nstudy){
		S.vR[i,,] = Corr.Cov(vR.impute[i,],N[i],index.list)
		tau.vR[i,,] <- solve(S.vR[i,,])
	}	
	return(list(S.vR = S.vR,tau.vR = tau.vR))
}

# generate data for meta-analytic CFA 
# the two-level model of OSMASEM is used
Gen.CFA.data <- function(Nstudy,mu.N,Model.list,p,missing,N=NULL){

	beta = Model.list$beta
	tau = Model.list$tau
	ind = Model.list$ind
	Z = Model.list$Z
	pp = Model.list$pp
	j = Model.list$j
	j10 = Model.list$j10
	k = Model.list$k
	k10 = Model.list$k10
	vil = Model.list$vil	

	# predicted SEM parameters
	coefM <- Z%*%t(beta)

	# predicted part of the true correlation vector for each study
	vPs = t(apply(coefM,1,function(x,pp,j,k,j10,k10,ind){
		r = rep(NA,pp)
		for(vi in 1:pp){
		  r[vi] = x[j[vi]]*x[k[vi]]+x[j10[vi]]*x[k10[vi]]*ind[vi]		
		}
		return(r)
	},pp=pp,j=j,k=k,j10=j10,k10=k10,ind=ind) )

	# true correlation vector for each study
	if(tau[1]>0){
	   vP = t(apply(vPs,1,function(x,tau,pp){
		r = rep(NA,pp)
		for(vi in 1:pp){ r[vi] = rnorm(1,x[vi],sd=tau[vi]) }
		return(r)
	   },tau=tau,pp=pp) )
	}else{ vP=vPs }

	# sample size for each study
	if(is.null(N)){
	  N <- rzinb(n =Nstudy, k =0.8, lambda=round(mu.N*0.2), omega = 0)
	  N <- N + round(mu.N*0.8)
	}

	# observed correlations
	vR = matrix(NA,Nstudy,pp)
	for(studyi in 1:Nstudy){
		Pm = v2m(vP[studyi,],p,T)
		Pm = nearPD(Pm,corr=T)$mat
		Ri = cor(mvrnorm(N[studyi],rep(0,p),Pm))
		vR[studyi,] = Ri[lower.tri(Ri)]	
	}

	#source(paste(wd,'RealData.R',sep=''))
	#vR = Make.Missing2(vR,missing,miss.rate,N)	# generate missing values
	return(list(j=j,k=k,vil=vil,pp=pp,N=N,vR=vR,Z=Z))
}

d4osmasem <- function(dsim){
	j = dsim$j
	vR = dsim$vR
	N = dsim$N
	Z = as.matrix(dsim$Z)

	p = max(j)	
	R.l = as.list(as.data.frame(t(vR)))
	Mat = lapply(R.l,function(x,p) v2m(x,p,T),p=p) 
	my.df = Cor2DataFrame(Mat,N,acov = 'weighted')
	my.df$data = data.frame(my.df$data,covariate=scale(Z[,1]),check.names = FALSE)
	return(my.df)
}

wbugs <-function(data,initsl,prm,mfn,
	nchains=1,niter=60000,nburnin=30000,nthin=1,wd,
	diagm){
# data: a named list of the data in the likelihood model for OpenBUGS
# initsl: a list with nchains elements; each element is a list of starting values
# prm: vector of names of the parameters to save
# mfn: the file name of the likelihood model for OpenBUGS
# diagm: name of the convergence diagnostic method; either 'Geweke' or 'Gelman'
# The function checks convergence every niter-nburnin iterations
	
	fit = bugs(data,initsl,prm,mfn,
		n.chains=nchains,n.iter=niter,n.burnin=nburnin,n.thin=1,
		debug=F,saveExec=T,working.directory = wd)

	for(tryi in 2:20){
		print(paste0('Iteration: ',tryi*(niter-nburnin)))
		fit.coda = read.openbugs(stem="",thin = nthin)
		del.id = na.omit(match(c('ppp'),varnames(fit.coda)))
		print(summary(fit.coda),3)
		if(diagm=='Geweke'){
			if(length(del.id)>0){
				tmp.conv = geweke.diag(fit.coda[,-del.id])[[1]]$z
			}else{ tmp.conv = geweke.diag(fit.coda)[[1]]$z }
			crit = (sum((abs(tmp.conv)>1.96),na.rm = T)==0)
		}else if(diagm=='Gelman'){
			if(length(del.id)>0){
				tmp.conv = gelman.diag(fit.coda)$psrf[-del.id,2]
			}else{ tmp.conv = gelman.diag(fit.coda)$psrf[,2] }
			crit = (sum((tmp.conv>1.1),na.rm = T)==0)
		}
		if(crit){
			print(tmp.conv)
			print(summary(fit.coda),3)	
			break
		}else{	
			fit = bugs(data,initsl,prm,mfn,
			n.chains=nchains,n.iter=niter-nburnin+1,n.burnin=1,n.thin=1,
			restart=T,saveExec=T,working.directory = wd)
		}
	}
	ppp.id = match('ppp',prm)
	sel = NA
	if(is.na(ppp.id)){
		nprm = length(prm)
		for(i in 1:nprm){ 
			sel = c(sel,grep(prm[i],rownames(summary(fit.coda)$quantiles)))
		}
	}else{
		prm = prm[-ppp.id]
		nprm = length(prm)
		for(i in 1:nprm){ 
			sel = c(sel,grep(prm[i],rownames(summary(fit.coda)$quantiles))) 
		}
	}
	sel = sel[-1]
	sel = unique(sel)
	
	if(is.na(ppp.id)){ est = round(summary(fit.coda)$quantiles[sel,'50%'],3)
	}else{
		est = round(c(summary(fit.coda)$quantiles[sel,'50%'],
		summary(fit.coda)$statistics['ppp','Mean']),3)
	}
	psd = round(summary(fit.coda)$statistics[sel,'SD'],3)
	if(diagm=='Geweke'){
		CIl = round(HPDinterval(fit.coda,prob = .95)[[1]][sel,1],3)
		CIu = round(HPDinterval(fit.coda,prob = .95)[[1]][sel,2],3)
	}else if(diagm=='Gelman'){
		fit.coda.l = do.call(rbind,fit.coda)
		HPDCI = HPDinterval(mcmc(fit.coda.l),prob = .95)
		CIl = HPDCI[sel,1]
		CIu = HPDCI[sel,2]
	}
	sel.muL = grep('mu.',names(est))
	sel.sdL = grep('sd.',names(est))
	CVl = round(est[sel.muL] - 1.28*est[sel.sdL],3)
	CVu = round(est[sel.muL] + 1.28*est[sel.sdL],3)
	
	conv = round(c(tryi,tmp.conv),3)
	return(list(est=est,psd=psd,CIl=CIl,CIu=CIu,CVl=CVl,CVu=CVu,conv=conv,
		DIC=fit$DIC,fit.coda=fit.coda))
}
```

# BMASEM
## Data preparation
```{r}
# remove multiple correlations from the same study
sid = dat[,'study']
sel.id = (duplicated(sid)==0)
dat = dat[sel.id,]

vR	= as.matrix(dat[,c('rXM','rXY','rMY')]) # bivariate correlations
N	= dat[,'N'] # individual study sample sizes
Nstudy	= nrow(dat) # number of studies
mu.N	= mean(N) # mean sample size per study

# Coordinations (matrix <-> vector)
p	= 3 # number of observed variables
pp 	= p*(p-1)/2 # number of bivariate correlations
index.list = jkvil(p)

# Compute level-1 error covariance matrix 
# Or covariance matrix of observed correlation vectors 
vR.bar = apply(vR,2,mean,na.rm = TRUE)
vR.impute = Mimpute(vR,N,'MCAR')
Stau.vR <- Vj(vR.bar,N,pp,Nstudy,index.list)
tau.vR <- Stau.vR$tau.vR; 

# Hyperparameters for priors (additional error term)
I3 = diag(1,3); u0 = rep(0,3);mu.vR.psi = rep(0,pp)
df.prelim = 100*pp/mu.N+pp
alpha.prior.vE = (df.prelim-pp+1)/2
beta.prior.vE = alpha.prior.vE*(0.3/mu.N)
```

## Model fitting
```{r}
data<-list("Nstudy","N","mu.N",'p',"pp","vR","tau.vR","mu.vR.psi",
	'alpha.prior.vE','beta.prior.vE','u0','I3') #data

vR.inits = vR.impute; vR.inits[which(is.na(vR)==0,arr.ind = TRUE)] = NA
initsl <- list(list(mu.a=0,mu.b=0,mu.cp=0,tau.u=diag(100,3),xi=rep(1,3),tau.R = 100,
	vR.psi = matrix(0,Nstudy,pp),vR = vR.inits)) # initial values

prm = c('mu.a','mu.b','mu.cp','mu.ab','sd.a','sd.b','sd.cp','sd.ab',
	'rho.ab','rho.acp','rho.bcp') # Parameters to save; 
model.fn = 'Mediation_Random.txt' # Model file name

# stop every 30000 iterations to check whether convergence is achieved
fit = wbugs(data,initsl,prm,model.fn,
		nchains=1,niter=60000,nburnin=30000,nthin=1,wd,diagm='Geweke')
fit[-9]
```

# OSMASEM
## Data preparation
```{r}
MFd	= vector('list',Nstudy)
Mat	= matrix(0,3,3)
for(studyi in 1:Nstudy){
	Mat[lower.tri(Mat)] = vR[studyi,]
	Mat[upper.tri(Mat)] = vR[studyi,]
	diag(Mat) = 1
	MFd[[studyi]] = Mat
}

## Create a dataframe with the data and the asymptotic variances and covariances (acov)
my.df <- Cor2DataFrame(MFd, N, acov = "weighted")
## Moderator Female proportion (standardized)
my.df$data <- data.frame(my.df$data,check.names=FALSE)
summary(my.df)
```

## Model fitting
```{r}
## Specify the mediation model
model0 <- "Y ~ M + X; M ~ X; X ~~ 1*X"
RAM0 <- lavaan2RAM(model0, obs.variables = c("X","M","Y"))

## Create matrices with implicit diagonal constraints
M0 <- create.vechsR(A0=RAM0$A, S0=RAM0$S, F0=RAM0$F)

## Create heterogeneity variances
T0 <- create.Tau2(RAM=RAM0, RE.type="Diag", Transform="expLog", RE.startvalues=0.05)

## Fit the bifactor model with One-Stage MASEM
fit0 <- osmasem(model.name="No moderator", Mmatrix=M0, Tmatrix=T0, data=my.df)
summary(fit0, fitIndices= T)

## SRMR
osmasemSRMR(fit0)
```

## Mean indirect effect and its SE
```{r}
# Delta method
parsnv = c('MONX','YONM') 
Sigma = vcov(fit0)[parsnv,parsnv]
est = coef(fit0)[parsnv]

ab.est = prod(est)
ab.se = sqrt(t(est[c(2,1)]) %*% Sigma %*% est[c(2,1)] )

c(ab.est,ab.se)
```